---
title: "Biostat 212a Homework 6"
subtitle: "Due Mar 22, 2024 @ 11:59PM"
author: "Kathy Hoang and 506333118"
date: today
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
engine: knitr
knitr:
  opts_chunk: 
    fig.align: 'center'
    # fig.width: 6
    # fig.height: 4
    message: FALSE
    cache: false
---

```{r clear environment}
# clear environment
rm(list = ls())
```

Load R libraries.
```{r load libraries}
library(tidyverse)
library(tidymodels)
library(readr)
library(tswge)
library(ggplot2)
library(yardstick)
library(tidyclust)
library(GGally)
library(gtsummary)
library(ranger)
library(ISLR2)
library(recipes)
library(tidytext)
library(tictoc) # for tuning enet

# speed up tuning process
library(doParallel)
library(foreach)

acfdf <- function(vec) {
  vacf <- acf(vec, plot = F)
  with(vacf, data.frame(lag, acf))
}

ggacf <- function(vec) {
  ac <- acfdf(vec)
  ggplot(data = ac, aes(x = lag, y = acf)) +
    geom_hline(aes(yintercept = 0)) +
    geom_segment(mapping = aes(xend = lag, yend = 0))
}

tplot <- function(vec) {
  df <- data.frame(X = vec, t = seq_along(vec))
  ggplot(data = df, aes(x = t, y = X)) +
    geom_line()
}
```
## New York Stock Exchange (NYSE) data (1962-1986) (140 pts)

::: {#fig-nyse}

<p align="center">
![](ISL_fig_10_14.pdf){width=600px height=600px}
</p>

Historical trading statistics from the New York Stock Exchange. Daily values of the normalized log trading volume, DJIA return, and log volatility are shown for a 24-year period from 1962-1986. We wish to predict trading volume on any day, given the history on all earlier days. To the left of the red bar (January 2, 1980) is training data, and to the right test data.

:::

The [`NYSE.csv`](https://raw.githubusercontent.com/ucla-econ-425t/2023winter/master/slides/data/NYSE.csv) file contains three daily time series from the New York Stock Exchange (NYSE) for the period Dec 3, 1962-Dec 31, 1986 (6,051 trading days).

- `Log trading volume` ($v_t$): This is the fraction of all outstanding shares that are traded on that day, relative to a 100-day moving average of past turnover, on the log scale.
    
- `Dow Jones return` ($r_t$): This is the difference between the log of the Dow Jones Industrial Index on consecutive trading days.
    
- `Log volatility` ($z_t$): This is based on the absolute values of daily price movements.

```{r read dataset}
# Read in NYSE data from url

url <- "https://raw.githubusercontent.com/ucla-biostat-212a/2024winter/master/slides/data/NYSE.csv"
NYSE <- read_csv(url)

NYSE
```
The **autocorrelation** at lag $\ell$ is the correlation of all pairs $(v_t, v_{t-\ell})$ that are $\ell$ trading days apart. These sizable correlations give us confidence that past values will be helpful in predicting the future.

```{r autocorrelation}
#| code-fold: true
#| label: fig-nyse-autocor
#| fig-cap: "The autocorrelation function for log volume. We see that nearby values are fairly strongly correlated, with correlations above 0.2 as far as 20 days apart."

ggacf(NYSE$log_volume) + ggthemes::theme_few()
```
Do a similar plot for (1) the correlation between $v_t$ and lag $\ell$ `Dow Jones return` $r_{t-\ell}$ and (2) correlation between $v_t$ and lag $\ell$ `Log volatility` $z_{t-\ell}$.

```{r autocorrelation dj return}
seq(1, 30) %>%
  map(function(x) {
    cor(NYSE$log_volume, lag(NYSE$DJ_return, x), use = "pairwise.complete.obs")
  }) %>%
  unlist() %>%
  tibble(lag = 1:30, cor = .) %>%
  ggplot(aes(x = lag, y = cor)) +
  geom_hline(aes(yintercept = 0)) +
  geom_segment(mapping = aes(xend = lag, yend = 0)) +
  ggtitle("AutoCorrelation between `log volume` and lagged `DJ return`")
```
Lecture Notes: Even though the 2 variables are different, there appears to be a
correlation between the log volume and lagged dj return, especially when lag
increases.

```{r autocorrelation log volatility}
seq(1, 30) %>%
  map(function(x) {
    cor(NYSE$log_volume, lag(NYSE$log_volatility, x),
      use = "pairwise.complete.obs"
    )
  }) %>%
  unlist() %>%
  tibble(lag = 1:30, cor = .) %>%
  ggplot(aes(x = lag, y = cor)) +
  geom_hline(aes(yintercept = 0)) +
  geom_segment(mapping = aes(xend = lag, yend = 0)) +
  ggtitle("AutoCorrelation between `log volume` and lagged `log volatility`")
```

### Project goal

Our goal is to forecast daily `Log trading volume`, using various machine learning algorithms we learnt in this class. 

The data set is already split into train (before Jan 1st, 1980, $n_{\text{train}} = 4,281$) and test (after Jan 1st, 1980, $n_{\text{test}} = 1,770$) sets.

<!-- Include `day_of_week` as a predictor in the models. -->

In general, we will tune the lag $L$ to acheive best forecasting performance. In this project, we would fix $L=5$. That is we always use the previous five trading days' data to forecast today's `log trading volume`.

Pay attention to the nuance of splitting time series data for cross validation. Study and use the [`time-series`](https://www.tidymodels.org/learn/models/time-series/) functionality in tidymodels. Make sure to use the same splits when tuning different machine learning algorithms.

Use the $R^2$ between forecast and actual values as the cross validation and test evaluation criterion.

### Baseline method (20 pts)

We use the straw man (use yesterday’s value of `log trading volume` to predict that of today) as the baseline method. Evaluate the $R^2$ of this method on the test data.

```{r my baseline method}
# MY SOLUTION (Prof Zhou confirmed it's correct)
# Baseline method

NYSE |> head()

# don't need this, it was already split oops
# train (before Jan 1st, 1980)
# train <- NYSE |> filter(year(NYSE$date) < 1980)
# train
#
# # test (after Jan 1st, 1980)
# test <- NYSE |> filter(year(NYSE$date) >= 1980)
# test

# THERES ALREADY A BINARY TRAIN COLUMN (T/F)
train <- NYSE |> filter(train)
train
test <- NYSE |> filter(!train)
test

# dont need to split train/test, but we do need to split for
# cross fold time series

# Use lag variable to shift back by 1 day (time series)
yday <- lag(test$log_volume, 1)

# Predict

# Calculate R^2
# use cor function to get R
r_squared_baseline <- cor(yday, test$log_volume, use = "pairwise.complete.obs")^2
r_squared_baseline
```

```{r prof baseline method}
# PROFESSOR'S SOLUTION (this way helps set it up for later problems w the
# lag variables)
L <- 5

# loop through lags 1-4
for (i in seq(1, L)) {
  NYSE <- NYSE |>
    # need to give var new name, and the name will change by which loop it is
    mutate(
      !!paste("DJ_return_lag", i, sep = "") := lag(NYSE$DJ_return, i),
      !!paste0("log_volume_lag", i, sep = "") := lag(NYSE$log_volume, i),
      !!paste("log_volatility_lag", i, sep = "") := lag(NYSE$log_volatility)
    )
}
NYSE <- NYSE |> na.omit()
NYSE
```

```{r split dataset}
# manually used the train column that was provided with the NYSE datset to split

# training set
NYSE_other <- NYSE %>%
  filter(train == "TRUE") %>%
  select(-train) %>%
  drop_na()
dim(NYSE_other)

# testing set
NYSE_test <- NYSE |>
  filter(train == "FALSE") |>
  select(-train) |>
  drop_na()
dim(NYSE_test)

# drop beginning trading days which lack some lagged variables
```
```{r strawman}
r2_test_strawman <- rsq_vec(
  NYSE_test$log_volume,
  lag(NYSE_test$log_volume, 1)
) |> round(2)
r2_test_strawman
```
### Autoregression (AR) forecaster (30 pts)

- Let
$$
y = \begin{pmatrix} v_{L+1} \\ v_{L+2} \\ v_{L+3} \\ \vdots \\ v_T \end{pmatrix},
\quad M = \begin{pmatrix}
1 & v_L & v_{L-1} & \cdots & v_1 \\
1 & v_{L+1} & v_{L} & \cdots & v_2 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & v_{T-1} & v_{T-2} & \cdots & v_{T-L}
\end{pmatrix}.
$$

- Fit an ordinary least squares (OLS) regression of $y$ on $M$, giving
$$
\hat v_t = \hat \beta_0 + \hat \beta_1 v_{t-1} + \hat \beta_2 v_{t-2} + \cdots +
\hat \beta_L v_{t-L},
$$
known as an **order-$L$ autoregression** model or **AR($L$)**.

-Before we start the model training, let’s talk about time series resampling. We will use the rolling_origin function in the rsample package to create a time series cross-validation plan.

-When the data have a strong time component, a resampling method should support modeling to estimate seasonal and other temporal trends within the data. A technique that randomly samples values from the training set can disrupt the model’s ability to estimate these patterns.

```{r temporal trends plot}
NYSE %>%
  ggplot(aes(x = date, y = log_volume)) +
  geom_line() +
  geom_smooth(method = "lm")
```

```{r wrong split}
wrong_split <- initial_split(NYSE_other)
# did not sort by date, also need to use initial_time_split

bind_rows(
  training(wrong_split) %>% mutate(type = "train"),
  testing(wrong_split) %>% mutate(type = "test")
) %>%
  ggplot(aes(x = date, y = log_volume, color = type, group = NA)) +
  geom_line()
```
```{r correct split}
correct_split <- initial_time_split(NYSE_other %>% arrange(date))
# a time split is needed to keep the time series in order
bind_rows(
  training(correct_split) %>% mutate(type = "train"),
  testing(correct_split) %>% mutate(type = "test")
) %>%
  ggplot(aes(x = date, y = log_volume, color = type, group = NA)) +
  geom_line()
```

```{r rolling origin}
rolling_origin(NYSE_other %>% arrange(date), initial = 30, assess = 7) %>%
  # sliding_period(NYSE_other %>% arrange(date), date, period = "day", lookback =
  # Inf, assess_stop = 1) %>%
  mutate(
    train_data = map(splits, analysis),
    test_data = map(splits, assessment)
  ) %>%
  select(-splits) %>%
  pivot_longer(-id) %>%
  filter(id %in% c("Slice0001", "Slice0002", "Slice0003")) %>%
  unnest(value) %>%
  ggplot(aes(x = date, y = log_volume, color = name, group = NA)) +
  geom_point() +
  geom_line() +
  facet_wrap(~id, scales = "fixed")
```

```{r sliding period}
sliding_period(NYSE_other %>% arrange(date),
  date,
  period = "month", lookback = Inf, assess_stop = 1
) %>%
  mutate(
    train_data = map(splits, analysis),
    test_data = map(splits, assessment)
  ) %>%
  select(-splits) %>%
  pivot_longer(-id) %>%
  filter(id %in% c("Slice001", "Slice002", "Slice003")) %>%
  unnest(value) %>%
  ggplot(aes(x = date, y = log_volume, color = name, group = NA)) +
  geom_point() +
  geom_line() +
  facet_wrap(~id, scales = "fixed")
```
- Tune AR(5) with elastic net (lasso + ridge) regularization using all 3 features on the training data, and evaluate the test performance. 

### Preprocessing

```{r elastic net recipe}
en_recipe <-
  recipe(
    log_volume ~ DJ_return_lag1 + log_volume_lag1 + log_volatility_lag1 +
      DJ_return_lag2 + log_volume_lag2 + log_volatility_lag2 +
      DJ_return_lag3 + log_volume_lag3 + log_volatility_lag3 +
      DJ_return_lag4 + log_volume_lag4 + log_volatility_lag4 +
      DJ_return_lag5 + log_volume_lag5 + log_volatility_lag5,
    data = NYSE_other
  ) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_normalize(all_numeric_predictors(), -all_outcomes()) %>%
  step_naomit(all_predictors()) %>%
  prep(data = NYSE_other)
```

### Model Training

```{r elastic net mod}
### Model
enet_mod <-
  # mixture = 0 (ridge), mixture = 1 (lasso)
  # mixture = (0, 1) elastic net
  # As an example, we set mixture = 0.5. It needs to be tuned.
  linear_reg(penalty = tune(), mixture = tune()) %>%
  set_engine("glmnet")
enet_mod
```

```{r bundle elastic net workflow}
sliding_period <- 30

en_wf <-
  workflow() %>%
  add_model(enet_mod) %>%
  add_recipe(en_recipe %>% step_indicate_na())
en_wf

folds <- NYSE_other %>%
  arrange(date) %>%
  sliding_period(date, period = "month", lookback = Inf, assess_stop = 1)
# rolling_origin(initial = 5, assess = 1)

month_folds <- NYSE_other %>%
  sliding_period(
    date,
    "month",
    lookback = Inf,
    skip = 4
  )

lambda_grid <-
  grid_regular(
    penalty(
      range = c(-8, 7),
      trans = log10_trans()
    ),
    levels = 3
  ) %>%
  expand_grid(mixture = c(0.01, 0.25, 0.5, 0.75, 0.99))
# tune mixture to be between 0 and 1 for enet

lambda_grid
```
Note: For reproducible results, please set the following code chunk to 
`eval=TRUE` to run the tuning process. To save time, I saved the fitted model
as an RDS file to reload more quickly for the final rendered report.

```{r tune elastic net, warning=FALSE, eval=FALSE}
# Using foreach parallel
num_cores <- detectCores() - 2
registerDoParallel(cores = num_cores)
en_fit <- en_wf |>
  tune_grid(en_wf,
    resamples = month_folds,
    grid = lambda_grid,
    metrics = metric_set(rmse, rsq)
  ) %>%
  collect_metrics()
en_fit
stopImplicitCluster()
```
```{r save elastic net rds, eval=FALSE}
# save random forest as .rds
saveRDS(en_fit, "elastic_net_model.rds")
```

```{r load elastic net rds}
en_fit <- readRDS("elastic_net_model.rds")
```

```{r best elastic net}
best_en_rmse <- en_fit %>%
  filter(.metric == "rmse") %>%
  filter(mean == min(mean))
best_en_rmse

best_en_rsq <- en_fit %>%
  filter(.metric == "rsq") %>%
  # dropna
  drop_na() %>%
  filter(mean == max(mean))
best_en_rsq

# print best rmse penalty and mixture
paste("Penalty for Best RMSE:", best_en_rmse$penalty[1])
# only extract first penalty if there are multiple
paste("Mixture for Best RMSE:", best_en_rmse$mixture[1])
```

```{r visualize elastic net}
# best mixture
en_fit %>%
  print(width = Inf) %>%
  filter(.metric == "rmse", mixture == best_en_rmse$mixture[1]) %>%
  ggplot(mapping = aes(x = penalty, y = mean)) +
  geom_point() +
  geom_line() +
  labs(x = "Penalty", y = "CV RMSE") +
  scale_x_log10(labels = scales::label_number())

# visualize by penalty
en_fit %>%
  print(width = Inf) %>%
  filter(.metric == "rmse") %>%
  ggplot(mapping = aes(x = penalty, y = mean)) +
  geom_point() +
  geom_line() +
  labs(x = "Penalty", y = "CV RMSE") +
  scale_x_log10(labels = scales::label_number())

# visualize by mixture
en_fit %>%
  print(width = Inf) %>%
  filter(.metric == "rmse") %>%
  ggplot(mapping = aes(x = mixture, y = mean)) +
  geom_point() +
  geom_line() +
  labs(x = "Mixture", y = "CV RMSE") +
  scale_x_log10(labels = scales::label_number())
```
- Hint: [Workflow: Lasso](https://ucla-biostat-212a.github.io/2024winter/slides/06-modelselection/workflow_lasso.html) is a good starting point.

### Random forest forecaster (30pts)

- Use the same features as in AR($L$) for the random forest. Tune the random forest and evaluate the test performance.

- Hint: [Workflow: Random Forest for Prediction](https://ucla-biostat-212a.github.io/2024winter/slides/08-tree/workflow_rf_reg.html) is a good starting point.

```{r random forest recipe}
rf_recipe <-
  recipe(
    log_volume ~ DJ_return_lag1 + log_volume_lag1 + log_volatility_lag1 +
      DJ_return_lag2 + log_volume_lag2 + log_volatility_lag2 +
      DJ_return_lag3 + log_volume_lag3 + log_volatility_lag3 +
      DJ_return_lag4 + log_volume_lag4 + log_volatility_lag4 +
      DJ_return_lag5 + log_volume_lag5 + log_volatility_lag5,
    data = NYSE_other
  ) %>%
  # step_dummy(all_nominal(), -all_outcomes()) %>%
  # step_normalize(all_numeric_predictors(), -all_outcomes()) %>%
  step_naomit(log_volume) %>%
  step_zv(all_numeric_predictors()) %>%
  prep(data = NYSE_other)
```

```{r random forest mod}
rf_mod <-
  rand_forest(
    mode = "regression",
    # Number of predictors randomly sampled in each split
    mtry = tune(),
    # Number of trees in ensemble
    trees = tune()
  ) %>%
  set_engine("ranger")
rf_mod
```
```{r bundle random forest workflow}
rf_wf <- workflow() %>%
  add_recipe(rf_recipe %>% step_indicate_na()) %>%
  add_model(rf_mod)
rf_wf

param_grid <- grid_regular(
  trees(range = c(100L, 300L)),
  mtry(range = c(1L, 5L)),
  levels = c(3, 5)
)
param_grid

set.seed(203)
folds <- vfold_cv(NYSE_other, v = 5)
folds

sliding_period <- 30

folds <- NYSE_other %>%
  arrange(date) %>%
  sliding_period(date, period = "month", lookback = Inf, assess_stop = 1)
# rolling_origin(initial = 5, assess = 1)


month_folds <- NYSE_other %>%
  sliding_period(
    date,
    "month",
    lookback = Inf,
    skip = 4
  )
```

Note: For reproducible results, please set the following code chunk to 
`eval=TRUE` to run the tuning process. To save time, I saved the fitted model
as an RDS file to reload more quickly for the final rendered report.

```{r fit random forest model, eval=FALSE}
# Using foreach parallel
num_cores <- detectCores() - 2
registerDoParallel(cores = num_cores)

# Fit C-V
system.time(rf_fit <- rf_wf %>%
  tune_grid(
    resamples = folds,
    grid = param_grid,
    metrics = metric_set(rmse, rsq)
  ))
rf_fit

stopImplicitCluster()
# user   system  elapsed
# 1809.238   12.370 1908.810
```
```{r save random forest rds, eval=FALSE}
# save random forest as .rds
saveRDS(rf_fit, "random_forest_model.rds")
```

```{r load random forest rds}
# load rds
rf_fit <- readRDS("random_forest_model.rds")
```


```{r visualize random forest model}
rf_fit %>%
  collect_metrics() %>%
  print(width = Inf) %>%
  filter(.metric == "rmse") %>%
  mutate(mtry = as.factor(mtry)) %>%
  ggplot(mapping = aes(x = trees, y = mean, color = mtry)) +
  # geom_point() +
  geom_line() +
  labs(x = "Num. of Trees", y = "CV mse")
```

```{r best random forest model}
rf_fit %>%
  show_best(metric = "rmse")

best_rf_rmse <- rf_fit %>%
  select_best(metric = "rmse")
best_rf_rmse

# Final workflow
final_rf_wf <- rf_wf %>%
  finalize_workflow(best_rf_rmse)
final_rf_wf

final_rf_fit <-
  final_rf_wf %>%
  last_fit(correct_split)
final_rf_fit

final_rf_fit %>% collect_metrics()
```


### Boosting forecaster (30pts)

- Use the same features as in AR($L$) for the boosting. Tune the boosting algorithm and evaluate the test performance.

- Hint: [Workflow: Boosting tree for Prediction](https://ucla-biostat-212a.github.io/2024winter/slides/08-tree/workflow_boosting_reg.html) is a good starting point.

```{r boosting recipe}
gb_recipe <-
  recipe(
    log_volume ~ DJ_return_lag1 + log_volume_lag1 + log_volatility_lag1 +
      DJ_return_lag2 + log_volume_lag2 + log_volatility_lag2 +
      DJ_return_lag3 + log_volume_lag3 + log_volatility_lag3 +
      DJ_return_lag4 + log_volume_lag4 + log_volatility_lag4 +
      DJ_return_lag5 + log_volume_lag5 + log_volatility_lag5,
    data = NYSE_other
  ) %>%
  # # create traditional dummy variables (not necessary for random forest in R)
  # step_dummy(all_nominal()) %>%
  step_naomit(log_volume) %>%
  # zero-variance filter
  step_zv(all_numeric_predictors())
# # center and scale numeric data (not necessary for random forest)
# step_normalize(all_numeric_predictors()) %>%
# estimate the means and standard deviations
gb_recipe
```

```{r boosting mod}
gb_mod <-
  boost_tree(
    mode = "regression",
    trees = 500,
    tree_depth = tune(),
    learn_rate = tune()
  ) %>%
  set_engine("xgboost")
gb_mod
```

```{r bundle boosting workflow}
gb_wf <- workflow() %>%
  add_recipe(gb_recipe %>% step_indicate_na()) %>%
  add_model(gb_mod)
gb_wf

param_grid <- grid_regular(
  tree_depth(range = c(1L, 4L)),
  learn_rate(range = c(-3, -0.5), trans = log10_trans()),
  levels = c(4, 10)
)
param_grid

set.seed(203)
folds <- vfold_cv(NYSE_other, v = 5)
folds
```

Note: For reproducible results, please set the following code chunk to 
`eval=TRUE` to run the tuning process. To save time, I saved the fitted model
as an RDS file to reload more quickly for the final rendered report.

```{r fit boosting model, eval=FALSE}
# Using foreach parallel
num_cores <- detectCores() - 2
registerDoParallel(cores = num_cores)

system.time(
  gb_fit <- gb_wf %>%
    tune_grid(
      resamples = folds,
      grid = param_grid,
      metrics = metric_set(rmse, rsq)
    )
)
gb_fit
stopImplicitCluster()
# user  system elapsed
# 232.640   1.369  47.065
```
```{r save boosting rds, eval=FALSE}
# save boosting as .rds
saveRDS(gb_fit, "gradient_boosting_model.rds")
```

```{r load boosting rds}
# load boosting .rds
gb_fit <- readRDS("gradient_boosting_model.rds")
```

```{r visualize boosting model}
gb_fit %>%
  collect_metrics() %>%
  print(width = Inf) %>%
  filter(.metric == "rmse") %>%
  ggplot(mapping = aes(x = learn_rate, y = mean, color = factor(tree_depth))) +
  geom_point() +
  geom_line() +
  labs(x = "Learning Rate", y = "CV AUC") +
  scale_x_log10()
```
```{r}
gb_fit %>%
  show_best(metric = "rmse")

best_gb_rmse <- gb_fit %>%
  select_best(metric = "rmse")
best_gb_rmse

# Final workflow
final_gb_wf <- gb_wf %>%
  finalize_workflow(best_gb_rmse)
final_gb_wf

final_gb_fit <-
  final_gb_wf %>%
  last_fit(correct_split)
final_gb_fit

final_gb_fit %>% collect_metrics()
```


### Summary (30pts)

Your score for this question is largely determined by your final test performance.

Summarize the performance of different machine learning forecasters in the following format. 

| Method | CV $R^2$ | Test $R^2$ |
|:------:|:------:|:------:|:------:|
| Baseline | - - | 0.3483986 | |
| AR(5) | 0.1505741 | 0.2279518 | |
| Random Forest | 0.1612909  | 0.5804922 | |
| Boosting |0.1588874 | 0.5915135 | |

Note: Baseline is linear so there's no CV R^2

## ISL Exercise 12.6.13 (90 pts)

On the book website, www.statlearning.com, there is a gene expression
data set (Ch12Ex13.csv) that consists of 40 tissue samples with
measurements on 1,000 genes. The  rst 20 samples are from healthy
patients, while the second 20 are from a diseased group.

```{r}
# load library
library(workflows)
library(parsnip)
library(tidyclust)
library(tidyverse)
library(tidymodels)
library(RcppHungarian)
library(embed)
library(Matrix)
library(irlba)
library(recipes)
# install.packages("pheatmap")
library(pheatmap)
# install.packages("ggplotify")
library(ggplotify) ## to convert pheatmap to ggplot2
# install.packages("heatmaply")
library(heatmaply) ## for constructing interactive heatmap
library(remotes)
```

(a) Load in the data using read.csv(). You will need to select
header = F.

```{r}
ds <- read.csv("https://raw.githubusercontent.com/ucla-biostat-212a/2024winter/master/slides/data/Ch12Ex13.csv", header = F)

# ds <- read_csv("../../slides/data/Ch12Ex13.csv", col_names = paste("ID", 1:40, sep = ""))
```

### 12.6.13 (b) (30 pts)
(b) Apply hierarchical clustering to the samples using correlationbased
distance, and plot the dendrogram. Do the genes separate
the samples into the two groups? Do your results depend on the
type of linkage used?

Yes the gene mostly separates the samples into two groups, but it does depend on the
type of linkage used as the average linkage has three groups. The rest of the
linkage methods produce two groups, though they are all separated different.

#### Correlation-Based Distance dendrograms
```{r average}
corr_dist <- cor(ds)
corr_based_dist <- as.dist(1 - corr_dist)


avg <- hclust(
  # num_clusters = 3,
  corr_based_dist,
  method = "average"
)

plot(avg)

comp <- hclust(
  # num_clusters = 3,
  corr_based_dist,
  method = "complete"
)

plot(comp)

sing <- hclust(
  # num_clusters = 3,
  corr_based_dist,
  method = "single"
)

plot(sing)

cent <- hclust(
  # num_clusters = 3,
  corr_based_dist,
  method = "centroid"
)

plot(cent)
```
#### Average
```{r}
set.seed(838383)

# 	Average -> Mean inter-cluster dissimilarity. Compute all pairwise dissimilarities between the observations in cluster A and the observations in cluster B, and record the AVG of these dissimilarities.


hc_spec <- hier_clust(
  # num_clusters = 3,
  linkage_method = "average"
)


hc_fit <- hc_spec %>%
  fit(~.,
    data = as.data.frame(t(ds))
  )

hc_fit %>%
  summary()

hc_fit$fit %>% plot()
```

```{r }
grp <- factor(rep(c(1, 0), each = 20))

regression <- function(y) {
  sum <- summary(lm(y ~ grp))
  pv <- sum$coefficients[2, 4]
  return(pv)
}


out <- tibble(
  gene = seq(1, nrow(ds)),
  p_values = unlist(purrr::map(
    1:nrow(ds),
    ~ regression(as.matrix(ds)[.x, ])
  ))
)

out %>%
  arrange(p_values) %>%
  head(10)
```
```{r}
sig <- out %>%
  arrange(p_values) %>%
  filter(p_values < 0.05)
```

```{r}
# create data frame for annotations
dfh <- data.frame(sample = as.character(colnames(ds)), status = "disease") %>%
  column_to_rownames("sample")
dfh$status[seq(21, 40)] <- "healthy"
dfh
```
```{r}
pheatmap(ds[sig$gene, ],
  cluster_rows = FALSE, cluster_cols = T,
  scale = "row", annotation_col = dfh,
  annotation_colors = list(
    status = c(disease = "orange", healthy = "black")
  ),
  color = colorRampPalette(c("navy", "white", "red"))(50)
)
```

#### Complete
```{r Complete}
set.seed(838383)

# #Complete	-> Maximal inter-cluster dissimilarity. Compute all pairwise dissimilarities between the observations in cluster A and the observations in cluster B, and record the LARGEST of these dissimilarities.
hc_spec <- hier_clust(
  # num_clusters = 3,
  linkage_method = "complete"
)

hc_fit <- hc_spec %>%
  fit(~.,
    data = as.data.frame(t(ds))
  )

hc_fit %>%
  summary()

hc_fit$fit %>% plot()
```
```{r }
grp <- factor(rep(c(1, 0), each = 20))

regression <- function(y) {
  sum <- summary(lm(y ~ grp))
  pv <- sum$coefficients[2, 4]
  return(pv)
}


out <- tibble(
  gene = seq(1, nrow(ds)),
  p_values = unlist(purrr::map(
    1:nrow(ds),
    ~ regression(as.matrix(ds)[.x, ])
  ))
)

out %>%
  arrange(p_values) %>%
  head(10)
```
```{r}
sig <- out %>%
  arrange(p_values) %>%
  filter(p_values < 0.05)
```

```{r}
# create data frame for annotations
dfh <- data.frame(sample = as.character(colnames(ds)), status = "disease") %>%
  column_to_rownames("sample")
dfh$status[seq(21, 40)] <- "healthy"
dfh
```
```{r}
pheatmap(ds[sig$gene, ],
  cluster_rows = FALSE, cluster_cols = T,
  scale = "row", annotation_col = dfh,
  annotation_colors = list(
    status = c(disease = "lightblue1", healthy = "darkseagreen4")
  ),
  color = colorRampPalette(c("darkslategray3", "white", "darkseagreen2"))(50)
)
```
#### 
```{r }
set.seed(838383)

# Single	-> Maximal inter-cluster dissimilarity. Compute all pairwise dissimilarities between the observations in cluster A and the observations in cluster B, and record the SMALLEST of these dissimilarities.
hc_spec <- hier_clust(
  # num_clusters = 3,
  linkage_method = "single"
)


hc_fit <- hc_spec %>%
  fit(~.,
    data = as.data.frame(t(ds))
  )

hc_fit %>%
  summary()

hc_fit$fit %>% plot()
```
```{r }
grp <- factor(rep(c(1, 0), each = 20))

regression <- function(y) {
  sum <- summary(lm(y ~ grp))
  pv <- sum$coefficients[2, 4]
  return(pv)
}


out <- tibble(
  gene = seq(1, nrow(ds)),
  p_values = unlist(purrr::map(
    1:nrow(ds),
    ~ regression(as.matrix(ds)[.x, ])
  ))
)

out %>%
  arrange(p_values) %>%
  head(10)
```

```{r}
sig <- out %>%
  arrange(p_values) %>%
  filter(p_values < 0.05)
```

```{r}
# create data frame for annotations
dfh <- data.frame(sample = as.character(colnames(ds)), status = "disease") %>%
  column_to_rownames("sample")
dfh$status[seq(21, 40)] <- "healthy"
dfh
```
```{r}
pheatmap(ds[sig$gene, ],
  cluster_rows = FALSE, cluster_cols = T,
  scale = "row", annotation_col = dfh,
  annotation_colors = list(
    status = c(disease = "thistle1", healthy = "palevioletred3")
  ),
  color = colorRampPalette(c("mediumorchid4", "white", "lightpink2"))(50)
)
```
```{r centroid}
set.seed(838383)

# Centroid	--> Dissimilarity between the centroid for cluster A (a mean vector of length) and the centroid for cluster B. Centroid linkage can result in undesirable inversions.
hc_spec <- hier_clust(
  # num_clusters = 3,
  linkage_method = "centroid"
)


hc_fit <- hc_spec %>%
  fit(~.,
    data = as.data.frame(t(ds))
  )

hc_fit %>%
  summary()

hc_fit$fit %>% plot()
```
```{r }
grp <- factor(rep(c(1, 0), each = 20))

regression <- function(y) {
  sum <- summary(lm(y ~ grp))
  pv <- sum$coefficients[2, 4]
  return(pv)
}


out <- tibble(
  gene = seq(1, nrow(ds)),
  p_values = unlist(purrr::map(
    1:nrow(ds),
    ~ regression(as.matrix(ds)[.x, ])
  ))
)

out %>%
  arrange(p_values) %>%
  head(10)
```
```{r}
sig <- out %>%
  arrange(p_values) %>%
  filter(p_values < 0.05)
```

```{r}
# create data frame for annotations
dfh <- data.frame(sample = as.character(colnames(ds)), status = "disease") %>%
  column_to_rownames("sample")
dfh$status[seq(21, 40)] <- "healthy"
dfh
```

```{r}
pheatmap(ds[sig$gene, ],
  cluster_rows = FALSE, cluster_cols = T,
  scale = "row", annotation_col = dfh,
  annotation_colors = list(
    status = c(disease = "gold", healthy = "lightsalmon4")
  ),
  color = colorRampPalette(c("lightsalmon1", "white", "peachpuff1"))(50)
)
```

### PCA and UMAP (30 pts)

```{r merged data PCA, warning=FALSE}}
# Load the data

# 41 columns
merged_data <- cbind(ds, dfh)

# transposed to 1001 rows
merged_data_2 <- cbind(t(ds), dfh)
```

#### NON-TRANSPOSED VERSION
In this version, the samples are the rows and the genes are the columns. PCA
analyzes the variation among the samples, and will show how the samples are
clustered and separated based on their gene expression profiles. If the blue
and red points are mixed together, then the samples are not separated by their
gene expression profiles and suggests that overall patterns are similar between
the two groups (healthy/diseased).

```{r PCA nontransposed}
# NON-TRANSPOSED VERSION
pca_rec <- recipe(~., data = merged_data) %>%
  update_role(status, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())
pca_prep <- prep(pca_rec)
pca_prep

tidied_pca <- tidy(pca_prep, 2)

tidied_pca %>%
  filter(component %in% paste0("PC", 1:4)) %>%
  group_by(component) %>%
  top_n(8, abs(value)) %>%
  ungroup() %>%
  mutate(terms = reorder_within(terms, abs(value), component)) %>%
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~component, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Absolute value of contribution",
    y = NULL, fill = "Positive?"
  )

juice(pca_prep) %>%
  ggplot(aes(PC1, PC2, label = status)) +
  geom_point(aes(color = status), alpha = 0.7, size = 2) +
  # geom_text(check_overlap = TRUE, hjust = "inward") +
  labs(color = NULL)
```

#### TRANSPOSED VERSION
In this version, the samples are the columns and the genes are the rows. PCA
analyzes the variation among the gene expression variables. In this case, the
PCA will show how the genes are clustered and separated based on their 
patterns of expression. If the blue and red points are separated, then the
genes are differentially expressed between the two groups (healthy/diseased).

```{r PCA transposed}
# TRANSPOSED VERSION
pca_rec_2 <- recipe(~., data = merged_data_2) %>%
  update_role(status, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())
pca_prep_2 <- prep(pca_rec_2)
pca_prep_2

tidied_pca_2 <- tidy(pca_prep_2, 2)

tidied_pca_2 %>%
  filter(component %in% paste0("PC", 1:4)) %>%
  group_by(component) %>%
  top_n(8, abs(value)) %>%
  ungroup() %>%
  mutate(terms = reorder_within(terms, abs(value), component)) %>%
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~component, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Absolute value of contribution",
    y = NULL, fill = "Positive?"
  )

juice(pca_prep_2) %>%
  ggplot(aes(PC1, PC2, label = status)) +
  geom_point(aes(color = status), alpha = 0.7, size = 2) +
  # geom_text(check_overlap = TRUE, hjust = "inward") +
  labs(color = NULL)
```
As shown above, the transposed PCA was able to dichotimize the sample into
healthy and diseased groups, while the non-transposed PCA indicated that the 
samples mix together. The non-transposed PCA can be useful for understanding 
the variation among the samples. Since the samples appear to cluster together,
it suggests there is not a clear difference between the healthy and diseased.

In my opinion, the transposed PCA is more informative as it shows the separation 
of the samples based on their gene expression. Since the PCA was able to clearly 
distinguish between the healthy and diseased groups, it suggests that the gene
expression profiles are different between the two groups. While both versions 
offer valuable insights, the transposed is more suitable for this analyzing 
the overall patterns of gene expression. 

```{r}
umap_rec <- recipe(~., data = merged_data) %>%
  update_role(status, new_role = "id") %>%
  step_normalize(all_predictors()) %>%
  step_umap(all_predictors())
umap_prep <- prep(umap_rec)
umap_prep

#error with step_umap in prep
# function 'as_cholmod_sparse' not provided by package 'Matrix'
#notes: to solve this issue
# 1. Install gfortran 12.2 at the top of this 
# https://cran.r-project.org/bin/macosx/tools/
# 2. Restart RStudio
# 3. remove packages and install from the source with dependencies
#remove.packages("Matrix") 
#remove.packages("irlba") 
#install.packages("Matrix",type="source", dependencies=T) 
#install.packages("irlba",type="source", dependencies=T)
# 4. restart rstudio again
```
```{r}
juice(umap_prep) %>%
  ggplot(aes(UMAP1, UMAP2, label = status)) +
  geom_point(aes(color = status), alpha = 0.7, size = 2) +
  #  geom_text(check_overlap = TRUE, hjust = "inward") +
  labs(color = NULL)
```

### 12.6.13 (c) (30 pts)
(c) Your collaborator wants to know which genes differ the most
across the two groups. Suggest a way to answer this question,
and apply it here.

```{r}
set.seed(838383)
# pca <- pr.comp(ds) #uses SVD
```
